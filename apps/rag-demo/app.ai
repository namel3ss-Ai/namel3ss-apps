spec is "1.0"

capabilities:
  uploads
  custom_theme
  streaming

ui:
  theme is "modern"
  accent color is "blue"
  density is "comfortable"
  motion is "subtle"
  shape is "rounded"
  surface is "raised"
  primary color is "#007AFF"
  secondary color is "#5856D6"
  background color is "#F8FAFC"
  foreground color is "#0B1220"
  font family is "Inter"
  spacing scale is 1.2
  border radius is 6
  shadow level is 2

policy
  allow ingestion.run
  allow ingestion.review
  allow ingestion.override
  allow retrieval.include_warn

ai "rag_writer_ai":
  provider is "mock"
  model is "mock:rag-writer"
  system_prompt is "You are a grounded RAG assistant. Summarize only with cited evidence."
  memory:
    short_term is 0
    semantic is false
    profile is false

foreign python function "normalize_query_text"
  input
    query is text
  output is text

foreign python function "extract_query_keywords"
  input
    query is text
  output is list of text

record "DocumentLibrary":
  fields:
    id is text must be present
    upload_id is text must be present
    document_id is text must be present
    source_name is text must be present
    source_type is text must be present
    status is text must be present
    quality is text must be present
    selected is boolean must be present
    status_label is text must be present
    scope_label is text must be present
    weight is number must be present
    tag is text must be present
    quality_note is text must be present

record "ExampleQuestion":
  fields:
    id is number must be present
    query is text must be present
    route is text must be present
    hint is text must be present

record "Question":
  fields:
    id is number must be present
    query is text must be present
    route is text must be present
    source_scope is text must be present

record "QueryProfile":
  fields:
    id is number must be present
    raw_query is text must be present
    normalized_query is text must be present
    route is text must be present
    keywords is json must be present
    active_documents is json must be present
    active_scopes is json must be present

record "Answer":
  fields:
    id is number must be present
    query is text must be present
    answer_text is text must be present
    citations is json must be present
    trusted is boolean must be present
    trust_score is number must be present
    confidence is number must be present
    source_count is number must be present
    mode is text must be present

record "CitationCard":
  fields:
    id is number must be present
    answer_id is number must be present
    source_name is text must be present
    source_id is text must be present
    chunk_id is text must be present
    document_id is text must be present
    page_number is number must be present
    page_label is text must be present
    snippet is text must be present

record "RetrievalCandidate":
  fields:
    query_id is number must be present
    rank is number must be present
    chunk_id is text must be present
    source_name is text must be present
    page_number is number must be present
    chunk_index is number must be present
    ingestion_phase is text must be present
    tier is text must be present
    semantic_rank is number must be present
    lexical_rank is number must be present
    lexical_hits is number must be present
    source_weight is number must be present
    merged_score is number must be present
    decision is text must be present
    reason is text must be present
    snippet is text must be present

record "RankingDecision":
  fields:
    query_id is number must be present
    rank is number must be present
    chunk_id is text must be present
    tier is text must be present
    semantic_rank is number must be present
    lexical_rank is number must be present
    lexical_hits is number must be present
    source_weight is number must be present
    merged_score is number must be present
    selected is boolean must be present
    reason is text must be present

record "ExplainSummary":
  fields:
    query is text must be present
    retrieval_mode is text must be present
    route is text must be present
    candidate_count is number must be present
    semantic_candidate_count is number must be present
    lexical_candidate_count is number must be present
    final_selection is json must be present
    ordering is text must be present
    rerank_policy is text must be present
    expansion_mode is text must be present
    chunking_config is text must be present
    citation_status is text must be present
    citation_count is number must be present
    provider_mode is text must be present

record "ExplainCandidate":
  fields:
    query is text must be present
    order is number must be present
    chunk_id is text must be present
    ingestion_phase is text must be present
    keyword_overlap is number must be present
    page_number is number must be present
    chunk_index is number must be present
    decision is text must be present
    reason is text must be present

record "Notice":
  fields:
    id is text must be present
    message is text must be present

contract flow "seed_examples":
  input:
  output:
    status is text

contract flow "initialize_scope_defaults":
  input:
  output:
    status is text

contract flow "sync_library":
  input:
  output:
    status is text

contract flow "seed_sample_corpus":
  input:
  output:
    status is text

contract flow "prepare_query_profile":
  input:
    query is text
  output:
    normalized_query is text
    keywords is json
    route is text

contract flow "ingest_selected":
  input:
  output:
    status is text

contract flow "ask_question":
  input:
    message is text
    offline is boolean
  output:
    answer_text is text
    mode is text

contract flow "run_demo_mode_path":
  input:
  output:
    status is text
    mode is text
    answer_text is text

flow "seed_examples": requires true
  find "ExampleQuestion" where true
  let example_count is list length of examplequestion_results
  if example_count is 0:
    create "ExampleQuestion" with map:
      "id" is 1
      "query" is "runtime enforces citations"
      "route" is "definition"
      "hint" is "Why citations are enforced."
    as ex_1

    create "ExampleQuestion" with map:
      "id" is 2
      "query" is "summarize the strongest evidence"
      "route" is "summary"
      "hint" is "Condense top supporting passages."
    as ex_2

    create "ExampleQuestion" with map:
      "id" is 3
      "query" is "compare indexing and retrieval in this corpus"
      "route" is "comparison"
      "hint" is "Compare ingestion and retrieval responsibilities."
    as ex_3

    create "ExampleQuestion" with map:
      "id" is 4
      "query" is "what does deterministic replay mean here"
      "route" is "definition"
      "hint" is "Explain reproducibility guarantees."
    as ex_4

  return map:
    "status" is "ok"

flow "initialize_scope_defaults": requires true
  set state.scope.options is list:
    map:
      "id" is "product"
      "name" is "Product manuals"
    map:
      "id" is "policy"
      "name" is "Policies"
    map:
      "id" is "general"
      "name" is "General docs"

  try:
    let active_scopes is state.scope.active
    let active_count is list length of active_scopes
    if active_count is 0:
      set state.scope.active is list:
        "product"
        "policy"
        "general"
  with catch err:
    set state.scope.active is list:
      "product"
      "policy"
      "general"

  try:
    let already_has_answer is state.answer.mode
    set state.answer.mode is already_has_answer
  with catch err:
    set state.answer with:
      query is ""
      answer_text is ""
      citations is list:
      citation_count is 0
      trusted is false
      trust_score is 0
      source_count is 0
      confidence is 0
      mode is "idle"
      available is false

  try:
    let has_drawer is state.drawer.has_selection
    set state.drawer.has_selection is has_drawer
  with catch err:
    set state.drawer with:
      has_selection is false

  return map:
    "status" is "ok"

flow "seed_sample_corpus": requires true
  let scope_init is call flow "initialize_scope_defaults":
    input:
    output:
      status

  let examples_init is call flow "seed_examples":
    input:
    output:
      status

  delete "DocumentLibrary" where true
  delete "Question" where true
  delete "QueryProfile" where true
  delete "Answer" where true
  delete "CitationCard" where true
  delete "RetrievalCandidate" where true
  delete "RankingDecision" where true
  delete "ExplainSummary" where true
  delete "ExplainCandidate" where true

  create "DocumentLibrary" with map:
    "id" is "sample-product"
    "upload_id" is "sample-product"
    "document_id" is "sample-product"
    "source_name" is "Product Manual"
    "source_type" is "Text"
    "status" is "indexed"
    "quality" is "pass"
    "selected" is true
    "status_label" is "Indexed • Text"
    "scope_label" is "product • priority 2"
    "weight" is 2
    "tag" is "product"
    "quality_note" is "Seeded sample source."
  as sample_product

  create "DocumentLibrary" with map:
    "id" is "sample-policy"
    "upload_id" is "sample-policy"
    "document_id" is "sample-policy"
    "source_name" is "Policy Handbook"
    "source_type" is "Text"
    "status" is "indexed"
    "quality" is "pass"
    "selected" is true
    "status_label" is "Indexed • Text"
    "scope_label" is "policy • priority 2"
    "weight" is 2
    "tag" is "policy"
    "quality_note" is "Seeded sample source."
  as sample_policy

  create "DocumentLibrary" with map:
    "id" is "sample-general"
    "upload_id" is "sample-general"
    "document_id" is "sample-general"
    "source_name" is "Architecture Notes"
    "source_type" is "Text"
    "status" is "indexed"
    "quality" is "pass"
    "selected" is true
    "status_label" is "Indexed • Text"
    "scope_label" is "general • priority 1"
    "weight" is 1
    "tag" is "general"
    "quality_note" is "Seeded sample source."
  as sample_general

  set state.index with:
    chunks is list:
      map:
        "chunk_id" is "sample-product-1"
        "upload_id" is "sample-product"
        "document_id" is "sample-product"
        "source_name" is "Product Manual"
        "page_number" is 1
        "chunk_index" is 1
        "ingestion_phase" is "seeded"
        "text" is "Indexing converts documents into deterministic chunks with stable IDs."
        "keywords" is list: "indexing", "chunks", "deterministic", "ids"
      map:
        "chunk_id" is "sample-product-2"
        "upload_id" is "sample-product"
        "document_id" is "sample-product"
        "source_name" is "Product Manual"
        "page_number" is 2
        "chunk_index" is 2
        "ingestion_phase" is "seeded"
        "text" is "Each chunk stores source metadata for citation cards and source previews."
        "keywords" is list: "chunk", "source", "metadata", "citation", "preview"
      map:
        "chunk_id" is "sample-product-3"
        "upload_id" is "sample-product"
        "document_id" is "sample-product"
        "source_name" is "Product Manual"
        "page_number" is 3
        "chunk_index" is 3
        "ingestion_phase" is "seeded"
        "text" is "Chat answers are expected to remain grounded in retrieved evidence."
        "keywords" is list: "chat", "answers", "grounded", "retrieved", "evidence"

      map:
        "chunk_id" is "sample-policy-1"
        "upload_id" is "sample-policy"
        "document_id" is "sample-policy"
        "source_name" is "Policy Handbook"
        "page_number" is 1
        "chunk_index" is 1
        "ingestion_phase" is "seeded"
        "text" is "Deterministic replay means repeated runs produce the same candidate ordering."
        "keywords" is list: "deterministic", "replay", "runs", "candidate", "ordering"
      map:
        "chunk_id" is "sample-policy-2"
        "upload_id" is "sample-policy"
        "document_id" is "sample-policy"
        "source_name" is "Policy Handbook"
        "page_number" is 2
        "chunk_index" is 2
        "ingestion_phase" is "seeded"
        "text" is "Trust badges are only shown when every claim can be tied to known citations."
        "keywords" is list: "trust", "badges", "claims", "known", "citations"
      map:
        "chunk_id" is "sample-policy-3"
        "upload_id" is "sample-policy"
        "document_id" is "sample-policy"
        "source_name" is "Policy Handbook"
        "page_number" is 3
        "chunk_index" is 3
        "ingestion_phase" is "seeded"
        "text" is "Diagnostics belong in debug surfaces, not in the default product UI."
        "keywords" is list: "diagnostics", "debug", "product", "ui"

      map:
        "chunk_id" is "sample-general-1"
        "upload_id" is "sample-general"
        "document_id" is "sample-general"
        "source_name" is "Architecture Notes"
        "page_number" is 1
        "chunk_index" is 1
        "ingestion_phase" is "seeded"
        "text" is "Hybrid retrieval combines semantic ranking with lexical keyword overlap."
        "keywords" is list: "hybrid", "retrieval", "semantic", "lexical", "keyword"
      map:
        "chunk_id" is "sample-general-2"
        "upload_id" is "sample-general"
        "document_id" is "sample-general"
        "source_name" is "Architecture Notes"
        "page_number" is 2
        "chunk_index" is 2
        "ingestion_phase" is "seeded"
        "text" is "Source weights can deterministically boost priority for preferred collections."
        "keywords" is list: "source", "weights", "deterministically", "priority", "collections"
      map:
        "chunk_id" is "sample-general-3"
        "upload_id" is "sample-general"
        "document_id" is "sample-general"
        "source_name" is "Architecture Notes"
        "page_number" is 3
        "chunk_index" is 3
        "ingestion_phase" is "seeded"
        "text" is "Small-to-big expansion includes neighboring chunks around selected evidence."
        "keywords" is list: "small", "big", "expansion", "neighboring", "evidence"

  set state.chat.messages is list:
  set state.chat.citations is list:
  set state.loading is false

  set state.answer with:
    query is ""
    answer_text is ""
    citations is list:
    citation_count is 0
    trusted is false
    trust_score is 0
    source_count is 0
    confidence is 0
    mode is "idle"
    available is false

  set state.drawer with:
    has_selection is false

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Sample corpus loaded. Ask a question to inspect deterministic retrieval."
  as seed_notice

  return map:
    "status" is "ok"

flow "sync_library": requires true
  let examples_init is call flow "seed_examples":
    input:
    output:
      status

  let scope_init is call flow "initialize_scope_defaults":
    input:
    output:
      status

  set state.upload_entries is list:
  let raw_uploads is list:
  try:
    let raw_uploads is state.uploads.documents
  with catch err:
    set raw_uploads is list:

  try:
    for each upload_entry in raw_uploads:
      set state.upload_entries is list append state.upload_entries with upload_entry
  with catch err:
    try:
      let upload_keys is map keys raw_uploads
      for each upload_key in upload_keys:
        let upload_entry is map get raw_uploads key upload_key
        set state.upload_entries is list append state.upload_entries with upload_entry
    with catch err:
      set state.upload_entries is list:

  let upload_count is list length of state.upload_entries
  if upload_count is 0:
    delete "Notice" where true
    create "Notice" with map:
      "id" is "current"
      "message" is "Add documents or load the sample corpus to begin."
    as notice_empty
    return map:
      "status" is "no_upload"

  for each file in state.upload_entries:
    set state.upload_id is ""
    try:
      let maybe_id is file.id
      if maybe_id is not "":
        set state.upload_id is maybe_id
    with catch err:
      set state.upload_id is state.upload_id

    if state.upload_id is "":
      try:
        let maybe_checksum is file.checksum
        if maybe_checksum is not "":
          set state.upload_id is maybe_checksum
      with catch err:
        set state.upload_id is state.upload_id

    if state.upload_id is "":
      try:
        let maybe_name_for_id is file.name
        if maybe_name_for_id is not "":
          set state.upload_id is maybe_name_for_id
      with catch err:
        set state.upload_id is state.upload_id

    if state.upload_id is "":
      set state.upload_id is "unknown-upload"

    find "DocumentLibrary" where upload_id is state.upload_id
    let existing_count is list length of documentlibrary_results
    if existing_count is 0:
      set state.source_name is state.upload_id
      try:
        let maybe_name is file.name
        if maybe_name is not "":
          set state.source_name is maybe_name
      with catch err:
        set state.source_name is state.source_name

      set state.source_type is "Text"
      try:
        let maybe_type is file.type
        if maybe_type is "application/pdf":
          set state.source_type is "PDF"
        else:
          if maybe_type is "text/plain":
            set state.source_type is "Text"
          else:
            if maybe_type is not "":
              set state.source_type is maybe_type
      with catch err:
        set state.source_type is state.source_type

      create "DocumentLibrary" with map:
        "id" is state.upload_id
        "upload_id" is state.upload_id
        "document_id" is state.upload_id
        "source_name" is state.source_name
        "source_type" is state.source_type
        "status" is "uploaded"
        "quality" is "pending"
        "selected" is true
        "status_label" is "Uploaded • " + state.source_type
        "scope_label" is "general • priority 1"
        "weight" is 1
        "tag" is "general"
        "quality_note" is "Upload synced. Re-index to make this source searchable."
      as library_row

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Uploads synced. Ingest selected sources to refresh retrieval index."
  as notice_synced

  return map:
    "status" is "ok"

flow "select_document": requires true
  try:
    let selected_upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where true
  let docs is documentlibrary_results
  delete "DocumentLibrary" where true

  for each doc in docs:
    set state.selected is false
    if doc.upload_id is selected_upload_id:
      set state.selected is true

    set state.scope_label is doc.tag

    create "DocumentLibrary" with map:
      "id" is doc.id
      "upload_id" is doc.upload_id
      "document_id" is doc.document_id
      "source_name" is doc.source_name
      "source_type" is doc.source_type
      "status" is doc.status
      "quality" is doc.quality
      "selected" is state.selected
      "status_label" is doc.status_label
      "scope_label" is state.scope_label
      "weight" is doc.weight
      "tag" is doc.tag
      "quality_note" is doc.quality_note
    as focused_doc

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Focused search on one source."
  as notice_focus

  return selected_upload_id

flow "add_document_selection": requires true
  try:
    let selected_upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where true
  let docs is documentlibrary_results
  delete "DocumentLibrary" where true

  for each doc in docs:
    set state.selected is doc.selected
    if doc.upload_id is selected_upload_id:
      set state.selected is true

    set state.scope_label is doc.tag

    create "DocumentLibrary" with map:
      "id" is doc.id
      "upload_id" is doc.upload_id
      "document_id" is doc.document_id
      "source_name" is doc.source_name
      "source_type" is doc.source_type
      "status" is doc.status
      "quality" is doc.quality
      "selected" is state.selected
      "status_label" is doc.status_label
      "scope_label" is state.scope_label
      "weight" is doc.weight
      "tag" is doc.tag
      "quality_note" is doc.quality_note
    as selected_doc

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Source added to active retrieval scope."
  as notice_add

  return selected_upload_id

flow "remove_document_selection": requires true
  try:
    let selected_upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where true
  let docs is documentlibrary_results
  delete "DocumentLibrary" where true

  for each doc in docs:
    set state.selected is doc.selected
    if doc.upload_id is selected_upload_id:
      set state.selected is false

    set state.scope_label is doc.tag

    create "DocumentLibrary" with map:
      "id" is doc.id
      "upload_id" is doc.upload_id
      "document_id" is doc.document_id
      "source_name" is doc.source_name
      "source_type" is doc.source_type
      "status" is doc.status
      "quality" is doc.quality
      "selected" is state.selected
      "status_label" is doc.status_label
      "scope_label" is state.scope_label
      "weight" is doc.weight
      "tag" is doc.tag
      "quality_note" is doc.quality_note
    as unselected_doc

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Source removed from active retrieval scope."
  as notice_remove_scope

  return selected_upload_id

flow "tag_document_product": requires true
  try:
    let upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where upload_id is upload_id
  let doc_count is list length of documentlibrary_results
  if doc_count is 0:
    return "not_found"

  let doc is list get documentlibrary_results at 0
  delete "DocumentLibrary" where upload_id is upload_id

  create "DocumentLibrary" with map:
    "id" is doc.id
    "upload_id" is doc.upload_id
    "document_id" is doc.document_id
    "source_name" is doc.source_name
    "source_type" is doc.source_type
    "status" is doc.status
    "quality" is doc.quality
    "selected" is doc.selected
    "status_label" is doc.status_label
    "scope_label" is "product"
    "weight" is doc.weight
    "tag" is "product"
    "quality_note" is doc.quality_note
  as tagged_product

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Tag set to product."
  as notice_tag_product

  return "ok"

flow "tag_document_policy": requires true
  try:
    let upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where upload_id is upload_id
  let doc_count is list length of documentlibrary_results
  if doc_count is 0:
    return "not_found"

  let doc is list get documentlibrary_results at 0
  delete "DocumentLibrary" where upload_id is upload_id

  create "DocumentLibrary" with map:
    "id" is doc.id
    "upload_id" is doc.upload_id
    "document_id" is doc.document_id
    "source_name" is doc.source_name
    "source_type" is doc.source_type
    "status" is doc.status
    "quality" is doc.quality
    "selected" is doc.selected
    "status_label" is doc.status_label
    "scope_label" is "policy"
    "weight" is doc.weight
    "tag" is "policy"
    "quality_note" is doc.quality_note
  as tagged_policy

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Tag set to policy."
  as notice_tag_policy

  return "ok"

flow "tag_document_general": requires true
  try:
    let upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where upload_id is upload_id
  let doc_count is list length of documentlibrary_results
  if doc_count is 0:
    return "not_found"

  let doc is list get documentlibrary_results at 0
  delete "DocumentLibrary" where upload_id is upload_id

  create "DocumentLibrary" with map:
    "id" is doc.id
    "upload_id" is doc.upload_id
    "document_id" is doc.document_id
    "source_name" is doc.source_name
    "source_type" is doc.source_type
    "status" is doc.status
    "quality" is doc.quality
    "selected" is doc.selected
    "status_label" is doc.status_label
    "scope_label" is "general"
    "weight" is doc.weight
    "tag" is "general"
    "quality_note" is doc.quality_note
  as tagged_general

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Tag set to general."
  as notice_tag_general

  return "ok"

flow "increase_document_weight": requires true
  try:
    let upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where upload_id is upload_id
  let doc_count is list length of documentlibrary_results
  if doc_count is 0:
    return "not_found"

  let doc is list get documentlibrary_results at 0
  set state.new_weight is doc.weight + 1
  if state.new_weight is greater than 3:
    set state.new_weight is 3

  delete "DocumentLibrary" where upload_id is upload_id
  create "DocumentLibrary" with map:
    "id" is doc.id
    "upload_id" is doc.upload_id
    "document_id" is doc.document_id
    "source_name" is doc.source_name
    "source_type" is doc.source_type
    "status" is doc.status
    "quality" is doc.quality
    "selected" is doc.selected
    "status_label" is doc.status_label
    "scope_label" is doc.tag
    "weight" is state.new_weight
    "tag" is doc.tag
    "quality_note" is doc.quality_note
  as weighted_up

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Source priority increased."
  as notice_weight_up

  return "ok"

flow "decrease_document_weight": requires true
  try:
    let upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where upload_id is upload_id
  let doc_count is list length of documentlibrary_results
  if doc_count is 0:
    return "not_found"

  let doc is list get documentlibrary_results at 0
  set state.new_weight is doc.weight - 1
  if state.new_weight is less than 1:
    set state.new_weight is 1

  delete "DocumentLibrary" where upload_id is upload_id
  create "DocumentLibrary" with map:
    "id" is doc.id
    "upload_id" is doc.upload_id
    "document_id" is doc.document_id
    "source_name" is doc.source_name
    "source_type" is doc.source_type
    "status" is doc.status
    "quality" is doc.quality
    "selected" is doc.selected
    "status_label" is doc.status_label
    "scope_label" is doc.tag
    "weight" is state.new_weight
    "tag" is doc.tag
    "quality_note" is doc.quality_note
  as weighted_down

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Source priority decreased."
  as notice_weight_down

  return "ok"

flow "ingest_selected": requires true
  let scope_init is call flow "initialize_scope_defaults":
    input:
    output:
      status

  find "DocumentLibrary" where selected is true
  let selected_docs is documentlibrary_results
  let selected_count is list length of selected_docs
  if selected_count is 0:
    delete "Notice" where true
    create "Notice" with map:
      "id" is "current"
      "message" is "Select at least one source before indexing."
    as notice_no_selection
    return map:
      "status" is "no_selection"

  try:
    let existing_chunks is state.index.chunks
    set state.existing_chunks is existing_chunks
  with catch err:
    set state.existing_chunks is list:

  set state.blocked_count is 0
  set state.indexed_count is 0
  set state.fallback_count is 0

  for each doc in selected_docs:
    set state.ingestion_ok is true
    set state.quality is "pass"
    set state.document_id is doc.document_id
    set state.source_name is doc.source_name
    set state.incoming_chunks is list:
    set state.block_reasons is list:
    set state.fallback_applied is false
    set state.fallback_reason_text is ""

    try:
      let out is call pipeline "ingestion":
        input:
          upload_id is doc.upload_id
        output:
          report
          ingestion
          index

      let report is map get out key "report"
      set state.ingestion is map get out key "ingestion"
      set state.index is map get out key "index"

      let provenance is map get report key "provenance"
      let maybe_document_id is map get provenance key "document_id"
      let maybe_source_name is map get provenance key "source_name"
      let maybe_quality is map get report key "status"

      if maybe_document_id is not "":
        set state.document_id is maybe_document_id
      if maybe_source_name is not "":
        set state.source_name is maybe_source_name
      if maybe_quality is not "":
        set state.quality is maybe_quality

      try:
        let reasons_from_report is map get report key "reasons"
        set state.block_reasons is reasons_from_report
      with catch err:
        set state.block_reasons is list:

      try:
        let incoming_chunks is map get state.index key "chunks"
        set state.incoming_chunks is incoming_chunks
      with catch err:
        set state.incoming_chunks is list:
    with catch err:
      set state.ingestion_ok is false
      set state.quality is "block"
      set state.incoming_chunks is list:
      set state.block_reasons is list:
        "pipeline_error"

    if state.quality is "block":
      let incoming_count is list length of state.incoming_chunks
      if incoming_count is 0:
        for each reason in state.block_reasons:
          if state.fallback_reason_text is "":
            set state.fallback_reason_text is reason
          else:
            set state.fallback_reason_text is state.fallback_reason_text + ", " + reason

        set state.fallback_text is "Fallback chunk for source " + state.source_name + ": full text extraction was blocked by ingestion quality checks. Use an OCR/searchable source for grounded answers."
        if state.fallback_reason_text is not "":
          set state.fallback_text is state.fallback_text + " Gate reasons: " + state.fallback_reason_text + "."

        set state.fallback_chunk with:
          chunk_id is doc.upload_id + ":fallback:1"
          upload_id is doc.upload_id
          document_id is state.document_id
          source_name is state.source_name
          page_number is 1
          chunk_index is 1
          ingestion_phase is "fallback_blocked"
          text is state.fallback_text
          keywords is list: "fallback", "blocked", "quality", "ocr", "searchable", "document", "source", "summary", "about"

        set state.incoming_chunks is list append state.incoming_chunks with state.fallback_chunk
        set state.quality is "warn"
        set state.fallback_applied is true
        set state.fallback_count is state.fallback_count + 1

    set state.filtered_chunks is list:
    for each chunk in state.existing_chunks:
      if chunk.upload_id is not doc.upload_id:
        set state.filtered_chunks is list append state.filtered_chunks with chunk

    set state.existing_chunks is state.filtered_chunks
    for each chunk in state.incoming_chunks:
      set state.existing_chunks is list append state.existing_chunks with chunk

    set state.doc_status is "indexed"
    set state.doc_status_label is "Indexed • " + doc.source_type
    set state.doc_quality_note is "Indexed and ready to answer questions."

    if state.quality is "block":
      set state.doc_status is "blocked"
      set state.doc_status_label is "Blocked • " + doc.source_type
      set state.doc_quality_note is "Blocked by quality checks. Upload a cleaner source, then index again."
      set state.blocked_count is state.blocked_count + 1
    else:
      if state.fallback_applied is true:
        set state.doc_status_label is "Indexed (Fallback) • " + doc.source_type
        set state.doc_quality_note is "Full text extraction was blocked. A fallback metadata chunk was indexed; upload OCR/searchable text for better grounding."
      set state.indexed_count is state.indexed_count + 1

    delete "DocumentLibrary" where upload_id is doc.upload_id
    create "DocumentLibrary" with map:
      "id" is doc.id
      "upload_id" is doc.upload_id
      "document_id" is state.document_id
      "source_name" is state.source_name
      "source_type" is doc.source_type
      "status" is state.doc_status
      "quality" is state.quality
      "selected" is doc.selected
      "status_label" is state.doc_status_label
      "scope_label" is doc.tag
      "weight" is doc.weight
      "tag" is doc.tag
      "quality_note" is state.doc_quality_note
    as indexed_doc

  set state.index with:
    chunks is state.existing_chunks

  delete "Notice" where true
  if state.blocked_count is greater than 0:
    if state.indexed_count is greater than 0:
      create "Notice" with map:
        "id" is "current"
        "message" is "Indexing completed with warnings. Some sources were blocked."
      as notice_partial
    else:
      create "Notice" with map:
        "id" is "current"
        "message" is "All selected sources were blocked by quality checks."
      as notice_blocked
  else:
    if state.fallback_count is greater than 0:
      create "Notice" with map:
        "id" is "current"
        "message" is "Indexing complete with fallback chunks. For stronger grounding, upload OCR/searchable documents."
      as notice_fallback
    else:
      create "Notice" with map:
        "id" is "current"
        "message" is "Indexing complete. Ask a question to test grounded retrieval."
      as notice_indexed

  return map:
    "status" is "ok"

flow "ingest_document": requires true
  try:
    let upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where upload_id is upload_id
  let doc_count is list length of documentlibrary_results
  if doc_count is 0:
    return "not_found"

  let doc is list get documentlibrary_results at 0
  let status is call flow "ingest_selected":
    input:
    output:
      status

  return upload_id

flow "remove_document": requires true
  try:
    let removed_upload_id is input.row.upload_id
  with catch err:
    return "missing_document"

  find "DocumentLibrary" where true
  let docs is documentlibrary_results
  delete "DocumentLibrary" where true

  for each doc in docs:
    if doc.upload_id is not removed_upload_id:
      create "DocumentLibrary" with doc as kept_doc

  try:
    let raw_uploads is state.uploads.documents
    set state.uploads.documents is list:
    try:
      for each upload_entry in raw_uploads:
        set state.entry_id is ""
        try:
          let maybe_id is upload_entry.id
          if maybe_id is not "":
            set state.entry_id is maybe_id
        with catch err:
          set state.entry_id is state.entry_id
        if state.entry_id is "":
          try:
            let maybe_checksum is upload_entry.checksum
            if maybe_checksum is not "":
              set state.entry_id is maybe_checksum
          with catch err:
            set state.entry_id is state.entry_id
        if state.entry_id is not removed_upload_id:
          set state.uploads.documents is list append state.uploads.documents with upload_entry
    with catch err:
      let upload_keys is map keys raw_uploads
      for each upload_key in upload_keys:
        if upload_key is not removed_upload_id:
          let upload_entry is map get raw_uploads key upload_key
          set state.uploads.documents is list append state.uploads.documents with upload_entry
  with catch err:
    set state.uploads.documents is list:

  try:
    let chunks is state.index.chunks
    set state.filtered_chunks is list:
    for each chunk in chunks:
      if chunk.upload_id is not removed_upload_id:
        set state.filtered_chunks is list append state.filtered_chunks with chunk
    set state.index with:
      chunks is state.filtered_chunks
  with catch err:
    set state.index with:
      chunks is list:

  delete "Question" where true
  delete "QueryProfile" where true
  delete "Answer" where true
  delete "CitationCard" where true
  delete "RetrievalCandidate" where true
  delete "RankingDecision" where true
  delete "ExplainSummary" where true
  delete "ExplainCandidate" where true

  set state.chat.messages is list:
  set state.chat.citations is list:

  set state.answer with:
    query is ""
    answer_text is ""
    citations is list:
    citation_count is 0
    trusted is false
    trust_score is 0
    source_count is 0
    confidence is 0
    mode is "idle"
    available is false

  set state.drawer with:
    has_selection is false

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Source removed. Conversation and explain logs were reset for deterministic replay."
  as notice_removed

  return removed_upload_id

flow "prepare_query_profile": requires true
  let normalized_query is normalize_query_text:
    query is input.query

  let keywords is extract_query_keywords:
    query is normalized_query

  set state.route is "lookup"
  set state.has_summary_hint is false
  set state.has_comparison_hint is false
  set state.has_definition_hint is false

  for each token in keywords:
    if token is "summary" or token is "summarize" or token is "overview":
      set state.has_summary_hint is true

    if token is "compare" or token is "comparison" or token is "difference" or token is "versus" or token is "vs":
      set state.has_comparison_hint is true

    if token is "define" or token is "definition" or token is "meaning" or token is "what":
      set state.has_definition_hint is true

  if state.has_comparison_hint is true:
    set state.route is "comparison"
  else:
    if state.has_summary_hint is true:
      set state.route is "summary"
    else:
      if state.has_definition_hint is true:
        set state.route is "definition"

  return map:
    "normalized_query" is normalized_query
    "keywords" is keywords
    "route" is state.route

flow "ask_question": requires true
  set state.loading is true

  let examples_init is call flow "seed_examples":
    input:
    output:
      status

  let scope_init is call flow "initialize_scope_defaults":
    input:
    output:
      status

  set state.q is ""
  try:
    let message_query is input.message
    if message_query is not "":
      set state.q is message_query
  with catch err:
    set state.q is state.q

  if state.q is "":
    try:
      let row_query is input.row.query
      if row_query is not "":
        set state.q is row_query
    with catch err:
      set state.q is state.q

  if state.q is "":
    set state.loading is false
    delete "Notice" where true
    create "Notice" with map:
      "id" is "current"
      "message" is "Ask a grounded question to search indexed documents."
    as notice_empty_query
    return map:
      "answer_text" is ""
      "mode" is "empty_query"

  set state.user_message with:
    role is "user"
    content is state.q
    actions is list: "copy", "expand", "view_sources"
    attachments is list:
    citations is list:
    trust is false
  try:
    let history is state.chat.messages
    set state.chat.messages is list append history with state.user_message
  with catch err:
    set state.chat.messages is list:
      state.user_message

  delete "RetrievalCandidate" where true
  delete "RankingDecision" where true
  delete "ExplainSummary" where true
  delete "ExplainCandidate" where true

  find "Question" where true
  let question_count is list length of question_results
  set state.query_id is question_count + 1

  let profile_out is call flow "prepare_query_profile":
    input:
      query is state.q
    output:
      normalized_query
      keywords
      route

  set state.normalized_query is map get profile_out key "normalized_query"
  set state.query_keywords is map get profile_out key "keywords"
  set state.query_route is map get profile_out key "route"

  create "Question" with map:
    "id" is state.query_id
    "query" is state.q
    "route" is state.query_route
    "source_scope" is "selected_documents"
  as question_row

  find "DocumentLibrary" where selected is true
  let selected_docs is documentlibrary_results

  set state.scope_docs is list:
  set state.active_upload_ids is list:

  try:
    let active_scopes is state.scope.active
    set state.active_scopes is active_scopes
  with catch err:
    set state.active_scopes is list:
      "product"
      "policy"
      "general"

  let active_scope_count is list length of state.active_scopes

  for each doc in selected_docs:
    set state.include_doc is false
    if active_scope_count is 0:
      set state.include_doc is true
    else:
      for each active_scope in state.active_scopes:
        if doc.tag is active_scope:
          set state.include_doc is true

    if state.include_doc is true:
      set state.scope_docs is list append state.scope_docs with doc
      set state.active_upload_ids is list append state.active_upload_ids with doc.upload_id

  create "QueryProfile" with map:
    "id" is state.query_id
    "raw_query" is state.q
    "normalized_query" is state.normalized_query
    "route" is state.query_route
    "keywords" is state.query_keywords
    "active_documents" is state.active_upload_ids
    "active_scopes" is state.active_scopes
  as profile_row

  set state.answer_text is ""
  set state.answer_citations is list:
  set state.answer_mode is "no_selection"
  set state.answer_confidence is 0
  set state.answer_source_count is 0
  set state.answer_trust_score is 0
  set state.answer_trusted is false

  set state.semantic_candidate_count is 0
  set state.lexical_candidate_count is 0
  set state.rank_counter is 0
  set state.active_chunks is list:
  set state.final_rows is list:
  set state.final_ids is list:

  let scoped_count is list length of state.scope_docs
  if scoped_count is 0:
    set state.answer_text is "No selected sources match your active scope. Add sources or update scope filters."
    set state.answer_mode is "no_selection"
  else:
    let chunks is list:
    try:
      let known_index is state.index
      let chunks is map get known_index key "chunks"
    with catch err:
      set chunks is list:

    set state.active_chunks is list:
    for each chunk in chunks:
      set state.include_chunk is false
      for each doc in state.scope_docs:
        if state.include_chunk is false:
          if doc.status is "indexed":
            if doc.upload_id is chunk.upload_id:
              set state.include_chunk is true
      if state.include_chunk is true:
        set state.active_chunks is list append state.active_chunks with chunk

    let active_chunk_count is list length of state.active_chunks
    if active_chunk_count is 0:
      set state.answer_text is "No indexed chunks exist in your active scope. One or more sources may be blocked by quality checks."
      set state.answer_mode is "no_indexed_chunks"
    else:
      set state.active_index with:
        chunks is state.active_chunks

      try:
        let retrieval_out is call pipeline "retrieval":
          input:
            query is state.normalized_query
            limit is 12
            tier is "auto"
            index is state.active_index
          output:
            report

        let retrieval_report is map get retrieval_out key "report"
        let semantic_results is list:
        try:
          let semantic_results is map get retrieval_report key "results"
        with catch err:
          set semantic_results is list:

        set state.semantic_results is semantic_results
      with catch err:
        set state.semantic_results is list:

      set state.semantic_candidate_count is list length of state.semantic_results

      set state.lexical_rows is list:
      set state.lexical_rank_counter is 0
      for each chunk in state.active_chunks:
        let chunk_keywords is list:
        try:
          let chunk_keywords is chunk.keywords
        with catch err:
          set chunk_keywords is list:

        set state.hit_count is 0
        for each qk in state.query_keywords:
          for each ck in chunk_keywords:
            if qk is ck:
              set state.hit_count is state.hit_count + 1

        if state.hit_count is greater than 0:
          set state.lexical_rank_counter is state.lexical_rank_counter + 1

          set state.source_weight is 1
          for each doc in state.scope_docs:
            if doc.upload_id is chunk.upload_id:
              set state.source_weight is doc.weight

          set state.lex_row with:
            chunk_id is chunk.chunk_id
            upload_id is chunk.upload_id
            document_id is chunk.document_id
            source_name is chunk.source_name
            page_number is chunk.page_number
            chunk_index is chunk.chunk_index
            ingestion_phase is chunk.ingestion_phase
            snippet is chunk.text
            lexical_hits is state.hit_count
            lexical_rank is state.lexical_rank_counter
            source_weight is state.source_weight
          set state.lexical_rows is list append state.lexical_rows with state.lex_row

      set state.lexical_candidate_count is list length of state.lexical_rows

      set state.merged_rows is list:
      set state.semantic_rank_counter is 0

      for each res in state.semantic_results:
        set state.semantic_rank_counter is state.semantic_rank_counter + 1

        set state.chunk_id is res.chunk_id
        set state.upload_id is ""
        set state.document_id is ""
        set state.source_name is "Source"
        set state.page_number is 1
        set state.chunk_index is 0
        set state.ingestion_phase is "unknown"
        set state.snippet is ""

        try:
          let maybe_upload is res.upload_id
          set state.upload_id is maybe_upload
        with catch err:
          set state.upload_id is state.upload_id

        try:
          let maybe_doc_id is res.document_id
          set state.document_id is maybe_doc_id
        with catch err:
          set state.document_id is state.document_id

        try:
          let maybe_source is res.source_name
          set state.source_name is maybe_source
        with catch err:
          set state.source_name is state.source_name

        try:
          let maybe_page is res.page_number
          set state.page_number is maybe_page
        with catch err:
          set state.page_number is state.page_number

        try:
          let maybe_chunk_index is res.chunk_index
          set state.chunk_index is maybe_chunk_index
        with catch err:
          set state.chunk_index is state.chunk_index

        try:
          let maybe_phase is res.ingestion_phase
          set state.ingestion_phase is maybe_phase
        with catch err:
          set state.ingestion_phase is state.ingestion_phase

        try:
          let maybe_snippet is res.text
          set state.snippet is maybe_snippet
        with catch err:
          set state.snippet is state.snippet

        for each chunk in state.active_chunks:
          if chunk.chunk_id is state.chunk_id:
            if state.upload_id is "":
              set state.upload_id is chunk.upload_id
            if state.document_id is "":
              set state.document_id is chunk.document_id
            if state.source_name is "Source":
              set state.source_name is chunk.source_name
            if state.page_number is 1:
              set state.page_number is chunk.page_number
            if state.chunk_index is 0:
              set state.chunk_index is chunk.chunk_index
            if state.ingestion_phase is "unknown":
              set state.ingestion_phase is chunk.ingestion_phase
            if state.snippet is "":
              set state.snippet is chunk.text

        set state.lexical_hits is 0
        set state.lexical_rank is 0
        for each lex in state.lexical_rows:
          if lex.chunk_id is state.chunk_id:
            set state.lexical_hits is lex.lexical_hits
            set state.lexical_rank is lex.lexical_rank

        set state.source_weight is 1
        for each doc in state.scope_docs:
          if doc.upload_id is state.upload_id:
            set state.source_weight is doc.weight

        set state.tier is "semantic_only"
        if state.lexical_hits is greater than 0:
          set state.tier is "hybrid_match"

        set state.merged_score is 100 - state.semantic_rank_counter
        set state.merged_score is state.merged_score + (state.lexical_hits * 10)
        set state.merged_score is state.merged_score + (state.source_weight * 5)

        set state.merged_row with:
          chunk_id is state.chunk_id
          upload_id is state.upload_id
          document_id is state.document_id
          source_name is state.source_name
          page_number is state.page_number
          chunk_index is state.chunk_index
          ingestion_phase is state.ingestion_phase
          snippet is state.snippet
          tier is state.tier
          semantic_rank is state.semantic_rank_counter
          lexical_rank is state.lexical_rank
          lexical_hits is state.lexical_hits
          source_weight is state.source_weight
          merged_score is state.merged_score
        set state.merged_rows is list append state.merged_rows with state.merged_row

      for each lex in state.lexical_rows:
        set state.exists is false
        for each merged in state.merged_rows:
          if merged.chunk_id is lex.chunk_id:
            set state.exists is true

        if state.exists is false:
          set state.merged_score is 30 + (lex.lexical_hits * 10)
          set state.merged_score is state.merged_score + (lex.source_weight * 5)

          set state.merged_row with:
            chunk_id is lex.chunk_id
            upload_id is lex.upload_id
            document_id is lex.document_id
            source_name is lex.source_name
            page_number is lex.page_number
            chunk_index is lex.chunk_index
            ingestion_phase is lex.ingestion_phase
            snippet is lex.snippet
            tier is "lexical_only"
            semantic_rank is 999
            lexical_rank is lex.lexical_rank
            lexical_hits is lex.lexical_hits
            source_weight is lex.source_weight
            merged_score is state.merged_score
          set state.merged_rows is list append state.merged_rows with state.merged_row

      set state.reranked_rows is list:

      for each ranked in state.merged_rows:
        if ranked.tier is "hybrid_match":
          if ranked.source_weight is greater than 1:
            set state.reranked_rows is list append state.reranked_rows with ranked

      for each ranked in state.merged_rows:
        if ranked.tier is "hybrid_match":
          if ranked.source_weight is 1:
            set state.reranked_rows is list append state.reranked_rows with ranked

      for each ranked in state.merged_rows:
        if ranked.tier is "semantic_only":
          if ranked.source_weight is greater than 1:
            set state.reranked_rows is list append state.reranked_rows with ranked

      for each ranked in state.merged_rows:
        if ranked.tier is "semantic_only":
          if ranked.source_weight is 1:
            set state.reranked_rows is list append state.reranked_rows with ranked

      for each ranked in state.merged_rows:
        if ranked.tier is "lexical_only":
          set state.reranked_rows is list append state.reranked_rows with ranked

      set state.top_k is 6
      if state.query_route is "summary":
        set state.top_k is 8
      else:
        if state.query_route is "comparison":
          set state.top_k is 8

      set state.rank_counter is 0
      set state.final_rows is list:
      set state.final_ids is list:

      for each ranked in state.reranked_rows:
        set state.rank_counter is state.rank_counter + 1

        set state.selected is false
        set state.decision is "skipped"
        if state.rank_counter is at most state.top_k:
          set state.selected is true
          set state.decision is "selected"
          set state.final_rows is list append state.final_rows with ranked
          set state.final_ids is list append state.final_ids with ranked.chunk_id

        set state.reason is "Semantic rank retained in deterministic order."
        if ranked.tier is "hybrid_match":
          set state.reason is "Selected for semantic + lexical agreement."
        else:
          if ranked.tier is "lexical_only":
            set state.reason is "Lexical-only support appended after semantic candidates."

        if ranked.source_weight is greater than 1:
          set state.reason is "Source weighting boosted this candidate tier."

        create "RankingDecision" with map:
          "query_id" is state.query_id
          "rank" is state.rank_counter
          "chunk_id" is ranked.chunk_id
          "tier" is ranked.tier
          "semantic_rank" is ranked.semantic_rank
          "lexical_rank" is ranked.lexical_rank
          "lexical_hits" is ranked.lexical_hits
          "source_weight" is ranked.source_weight
          "merged_score" is ranked.merged_score
          "selected" is state.selected
          "reason" is state.reason
        as ranking_entry

        create "RetrievalCandidate" with map:
          "query_id" is state.query_id
          "rank" is state.rank_counter
          "chunk_id" is ranked.chunk_id
          "source_name" is ranked.source_name
          "page_number" is ranked.page_number
          "chunk_index" is ranked.chunk_index
          "ingestion_phase" is ranked.ingestion_phase
          "tier" is ranked.tier
          "semantic_rank" is ranked.semantic_rank
          "lexical_rank" is ranked.lexical_rank
          "lexical_hits" is ranked.lexical_hits
          "source_weight" is ranked.source_weight
          "merged_score" is ranked.merged_score
          "decision" is state.decision
          "reason" is state.reason
          "snippet" is ranked.snippet
        as candidate_entry

        create "ExplainCandidate" with map:
          "query" is state.q
          "order" is state.rank_counter
          "chunk_id" is ranked.chunk_id
          "ingestion_phase" is ranked.ingestion_phase
          "keyword_overlap" is ranked.lexical_hits
          "page_number" is ranked.page_number
          "chunk_index" is ranked.chunk_index
          "decision" is state.decision
          "reason" is state.reason
        as explain_candidate

      let selected_count_final is list length of state.final_ids
      if selected_count_final is 0:
        set state.answer_text is "I could not find grounded support in your active sources for: " + state.normalized_query
        set state.answer_citations is list:
        set state.answer_mode is "no_support"
        set state.answer_confidence is 0
        set state.answer_source_count is 0
      else:
        set state.answer_citations is list:
        set state.context_lines is list:

        for each selected_chunk in state.final_rows:
          set state.citation_row with:
            title is selected_chunk.source_name
            source_id is selected_chunk.upload_id
            chunk_id is selected_chunk.chunk_id
            document_id is selected_chunk.document_id
            page_number is selected_chunk.page_number
            snippet is selected_chunk.snippet
          set state.answer_citations is list append state.answer_citations with state.citation_row
          set state.context_lines is list append state.context_lines with selected_chunk.snippet

        set state.context_text is ""
        for each line in state.context_lines:
          if state.context_text is "":
            set state.context_text is "- " + line
          else:
            set state.context_text is state.context_text + "\n- " + line

        set state.answer_source_count is selected_count_final
        set state.answer_confidence is 1

        set state.offline is false
        try:
          let offline is input.offline
          set state.offline is offline
        with catch err:
          set state.offline is false

        if state.offline is true:
          set state.answer_text is "Citations-only mode is active. Read the numbered source chips and verify each claim."
          set state.answer_mode is "citations_only"
        else:
          set state.ai_input is "Question: " + state.normalized_query + "\nEvidence:\n" + state.context_text
          try:
            ask ai "rag_writer_ai" with stream is true and input: state.ai_input as model_answer
            set state.answer_text is model_answer
            set state.answer_mode is "answer_stream"
          with catch err:
            set state.answer_text is "Answer provider fallback: review citations to verify grounded support."
            set state.answer_mode is "provider_fallback"

      set state.answer_trust_score is 0
      let citation_count is list length of state.answer_citations
      if citation_count is greater than 0:
        set state.answer_trust_score is 0.6
      if citation_count is greater than 1:
        set state.answer_trust_score is 0.75
      if citation_count is greater than 2:
        set state.answer_trust_score is 0.9
      if state.answer_mode is "no_support":
        set state.answer_trust_score is 0

      set state.answer_trusted is false
      if state.answer_trust_score is greater than 0.74:
        set state.answer_trusted is true

  set state.chat.citations is state.answer_citations

  find "Answer" where true
  let answer_count is list length of answer_results
  set state.answer_id is answer_count + 1

  create "Answer" with map:
    "id" is state.answer_id
    "query" is state.q
    "answer_text" is state.answer_text
    "citations" is state.answer_citations
    "trusted" is state.answer_trusted
    "trust_score" is state.answer_trust_score
    "confidence" is state.answer_confidence
    "source_count" is state.answer_source_count
    "mode" is state.answer_mode
  as answer_entry

  delete "CitationCard" where true
  set state.citation_id is 0
  for each citation in state.answer_citations:
    set state.citation_id is state.citation_id + 1
    create "CitationCard" with map:
      "id" is state.citation_id
      "answer_id" is state.answer_id
      "source_name" is citation.title
      "source_id" is citation.source_id
      "chunk_id" is citation.chunk_id
      "document_id" is citation.document_id
      "page_number" is citation.page_number
      "page_label" is "Page"
      "snippet" is citation.snippet
    as citation_entry

  set state.message_attachments is list:
  for each citation in state.answer_citations:
    set state.attachment with:
      title is citation.title
      type is "citation"
      source_id is citation.source_id
      snippet is citation.snippet
    set state.message_attachments is list append state.message_attachments with state.attachment

  set state.assistant_msg with:
    role is "assistant"
    content is state.answer_text
    citations is state.answer_citations
    trust is state.answer_trusted
    actions is list: "copy", "expand", "view_sources"
    attachments is state.message_attachments
    streaming is true
  set state.chat.messages is list append state.chat.messages with state.assistant_msg

  let final_citation_count is list length of state.answer_citations
  create "ExplainSummary" with map:
    "query" is state.q
    "retrieval_mode" is "hybrid_semantic_lexical"
    "route" is state.query_route
    "candidate_count" is state.rank_counter
    "semantic_candidate_count" is state.semantic_candidate_count
    "lexical_candidate_count" is state.lexical_candidate_count
    "final_selection" is state.final_ids
    "ordering" is "hybrid(weighted) -> semantic(weighted) -> lexical"
    "rerank_policy" is "hybrid+weight tiering with stable semantic and lexical tie-breakers"
    "expansion_mode" is "small_to_big_window_1"
    "chunking_config" is "runtime chunking with deterministic chunk ids and deterministic ordering"
    "citation_status" is "grounded"
    "citation_count" is final_citation_count
    "provider_mode" is state.answer_mode
  as summary_entry

  set state.answer with:
    query is state.q
    answer_text is state.answer_text
    citations is state.answer_citations
    citation_count is final_citation_count
    trusted is state.answer_trusted
    trust_score is state.answer_trust_score
    source_count is state.answer_source_count
    confidence is state.answer_confidence
    mode is state.answer_mode
    available is true

  if final_citation_count is greater than 0:
    let first_citation is list get state.answer_citations at 0
    set state.selected_citation_source is first_citation.source_id
    set state.drawer with:
      has_selection is true
  else:
    set state.selected_citation_source is ""
    set state.drawer with:
      has_selection is false

  delete "Notice" where true
  if state.answer_mode is "no_selection":
    create "Notice" with map:
      "id" is "current"
      "message" is "Select and index at least one source, then ask again."
    as notice_mode_no_selection
  else:
    if state.answer_mode is "no_indexed_chunks":
      create "Notice" with map:
        "id" is "current"
        "message" is "No indexed chunks are available. Check source status; blocked PDFs need OCR/searchable text."
      as notice_mode_no_indexed_chunks
    else:
      if state.answer_mode is "no_support":
        create "Notice" with map:
          "id" is "current"
          "message" is "No grounded support found. Rephrase using document terminology."
        as notice_mode_no_support
      else:
        if state.answer_mode is "provider_fallback":
          create "Notice" with map:
            "id" is "current"
            "message" is "Provider fallback active. Use citations and source previews to verify."
          as notice_mode_fallback
        else:
          if state.answer_mode is "citations_only":
            create "Notice" with map:
              "id" is "current"
              "message" is "Citations-only mode active. Open source previews before trusting conclusions."
            as notice_mode_citations_only
          else:
            create "Notice" with map:
              "id" is "current"
              "message" is "Answer ready with citations and trust signal."
            as notice_mode_answer

  set state.loading is false
  return map:
    "answer_text" is state.answer_text
    "mode" is state.answer_mode

flow "open_citation": requires true
  try:
    let source_name is input.row.source_name
    let source_id is input.row.source_id
    let chunk_id is input.row.chunk_id
    let document_id is input.row.document_id
    let page_number is input.row.page_number
    let snippet is input.row.snippet

    set state.selected_citation_source is source_id
    set state.drawer with:
      has_selection is true

    delete "Notice" where true
    create "Notice" with map:
      "id" is "current"
      "message" is "Source preview updated."
    as notice_open_citation

    return chunk_id
  with catch err:
    return "missing_citation"

flow "clear_sources_drawer": requires true
  set state.selected_citation_source is ""
  set state.drawer with:
    has_selection is false

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Source preview cleared."
  as notice_clear_drawer

  return "ok"

flow "run_demo_mode_path": requires true
  let seeded is call flow "seed_sample_corpus":
    input:
    output:
      status

  let demo_answer is call flow "ask_question":
    input:
      message is "runtime enforces citations"
      offline is false
    output:
      answer_text
      mode

  delete "Notice" where true
  create "Notice" with map:
    "id" is "current"
    "message" is "Guided run complete. Review citations and trust indicators."
  as notice_guided_demo

  return map:
    "status" is "ok"
    "mode" is map get demo_answer key "mode"
    "answer_text" is map get demo_answer key "answer_text"

flow "reset_demo": requires true
  delete "DocumentLibrary" where true
  delete "ExampleQuestion" where true
  delete "Question" where true
  delete "QueryProfile" where true
  delete "Answer" where true
  delete "CitationCard" where true
  delete "RetrievalCandidate" where true
  delete "RankingDecision" where true
  delete "ExplainSummary" where true
  delete "ExplainCandidate" where true
  delete "Notice" where true

  set state.chat.messages is list:
  set state.chat.citations is list:
  set state.loading is false

  set state.uploads.documents is list:
  set state.index with:
    chunks is list:

  set state.answer with:
    query is ""
    answer_text is ""
    citations is list:
    citation_count is 0
    trusted is false
    trust_score is 0
    source_count is 0
    confidence is 0
    mode is "idle"
    available is false

  set state.drawer with:
    has_selection is false

  let scope_init is call flow "initialize_scope_defaults":
    input:
    output:
      status

  let examples_init is call flow "seed_examples":
    input:
    output:
      status

  create "Notice" with map:
    "id" is "current"
    "message" is "Demo reset. Upload, ingest, ask, then verify every claim with sources."
  as notice_reset

  return "reset"

page "RAG Demo":
  layout:
    header:
      title is "Namel3ss RAG Chat"
      text is "Deterministic retrieval, visible citations, and trust-first answers."
      row:
        column:
          section "Status":
            list is Notice:
              variant is "single_line"
              item:
                primary is message
              empty_state: hidden
        column:
          section "Trust":
            trust_indicator from is state.answer.trusted

    sidebar_left:
      section "Documents":
        text is "Upload PDFs/text, sync library metadata, then index selected sources."

        upload documents:
          accept is "application/pdf,text/plain"
          multiple is true
          required is false
          label is "Add Documents"
          preview is true

        row:
          column:
            button "View uploads":
              variant is "secondary"
              calls flow "sync_library"
          column:
            button "Create index":
              variant is "secondary"
              calls flow "ingest_selected"

        scope_selector from is state.scope.options active in state.scope.active

        list is DocumentLibrary:
          variant is "two_line"
          selection is "multi"
          item:
            primary is source_name
            secondary is status_label
            meta is scope_label
          actions:
            action "Focus only this source":
              calls flow "select_document"
            action "Add to scope":
              calls flow "add_document_selection"
            action "Remove from scope":
              calls flow "remove_document_selection"
            action "Tag as Product":
              calls flow "tag_document_product"
            action "Tag as Policy":
              calls flow "tag_document_policy"
            action "Tag as General":
              calls flow "tag_document_general"
            action "Increase priority":
              calls flow "increase_document_weight"
            action "Decrease priority":
              calls flow "decrease_document_weight"
            action "Re-index":
              calls flow "ingest_document"
            action "Remove source":
              calls flow "remove_document"
          empty_state: hidden

    main:
      section "Conversation":
        chat:
          style is "bubbles"
          show_avatars is true
          group_messages is true
          actions are ["copy", "expand", "view_sources"]
          attachments are true
          messages from is state.chat.messages

        trust_indicator from is state.answer.trusted visible when state.drawer.has_selection

    drawer_right:
      section "Source Preview" visible when state.drawer.has_selection:
        list is CitationCard visible when state.drawer.has_selection:
          variant is "two_line"
          item:
            primary is source_name
            secondary is page_label
            meta is snippet
          actions:
            action "Open source preview":
              calls flow "open_citation"
          empty_state: hidden

        text is "Choose a citation card to inspect supporting evidence."

    footer:
      chat:
        style is "bubbles"
        show_avatars is true
        group_messages is true
        actions are ["copy", "expand", "view_sources"]
        streaming is true
        attachments are true
        thinking when is state.loading
        composer calls flow "ask_question"

      row:
        column:
          button "Reset source drawer":
            variant is "secondary"
            calls flow "clear_sources_drawer"

    diagnostics:
      section "Explain Summary":
        list is ExplainSummary:
          variant is "two_line"
          item:
            primary is retrieval_mode
            secondary is citation_status
            meta is ordering
          empty_state: hidden

      table is RetrievalCandidate:
        columns:
          include rank
          include decision
          include source_name
          include tier
          include lexical_hits
          include source_weight
          include merged_score
        sort:
          by is rank
          order is asc
        empty_state: hidden

      table is RankingDecision:
        columns:
          include rank
          include selected
          include tier
          include reason
          include merged_score
        sort:
          by is rank
          order is asc
        empty_state: hidden

      table is ExplainCandidate:
        columns:
          include order
          include decision
          include reason
          include page_number
          include chunk_index
          include ingestion_phase
          include keyword_overlap
        sort:
          by is order
          order is asc
        empty_state: hidden
