flow "ask_question": requires true
  try:
    let existing_semantic_k is state.retrieval.semantic_k
    set state.retrieval.semantic_k is existing_semantic_k
  with catch err:
    set state.retrieval with:
      semantic_weight is 60
      semantic_k is 8
      lexical_k is 8
      final_top_k is 6
  set state.loading is true
  set state.raw_message is ""
  set state.q is ""
  set state.has_query_text_input is false
  set state.scope_project_id is ""
  set state.scope_project_label is ""
  set state.scope_project_conflict is false
  set state.scope_document_ids is list:
  set state.scope_document_mode is "once"
  try:
    let message_query is input.message
    if message_query is not "":
      set state.raw_message is message_query
  with catch err:
    set state.raw_message is state.raw_message
  try:
    let scoped_query is input.query_text
    set state.has_query_text_input is true
    if scoped_query is not "":
      set state.q is scoped_query
  with catch err:
    set state.q is state.q
  try:
    let scoped_project_id is input.project_scope
    if scoped_project_id is not "":
      set state.scope_project_id is scoped_project_id
  with catch err:
    set state.scope_project_id is state.scope_project_id
  try:
    let scoped_project_label is input.project_scope_label
    if scoped_project_label is not "":
      set state.scope_project_label is scoped_project_label
  with catch err:
    set state.scope_project_label is state.scope_project_label
  try:
    let scoped_project_conflict is input.project_scope_conflict
    if scoped_project_conflict is true:
      set state.scope_project_conflict is true
  with catch err:
    set state.scope_project_conflict is state.scope_project_conflict
  try:
    let scoped_documents is input.document_scope
    for each scoped_document_id in scoped_documents:
      if scoped_document_id is not "":
        set state.scope_document_ids is list append state.scope_document_ids with scoped_document_id
  with catch err:
    set state.scope_document_ids is state.scope_document_ids
  try:
    let scoped_document_mode is input.document_scope_mode
    if scoped_document_mode is "add":
      set state.scope_document_mode is "add"
    else:
      if scoped_document_mode is "once":
        set state.scope_document_mode is "once"
  with catch err:
    set state.scope_document_mode is state.scope_document_mode
  set state.scope_document_ids_unique is list:
  for each scoped_document_id in state.scope_document_ids:
    set state.scope_document_seen is false
    for each known_scoped_document_id in state.scope_document_ids_unique:
      if known_scoped_document_id is scoped_document_id:
        set state.scope_document_seen is true
    if state.scope_document_seen is false:
      set state.scope_document_ids_unique is list append state.scope_document_ids_unique with scoped_document_id
  set state.scope_document_ids is state.scope_document_ids_unique
  if state.q is "":
    if state.has_query_text_input is false:
      if state.raw_message is not "":
        set state.q is state.raw_message
  try:
    let row_query is input.row.query
    if state.q is "":
      if row_query is not "":
        set state.q is row_query
  with catch err:
    set state.q is state.q
  if state.q is "":
    set state.loading is false
    delete "Notice" where true
    create "Notice" with map:
      "id" is "current"
      "message" is "Ask a grounded question to search indexed documents."
    as notice_empty_query
    return map:
      "answer_text" is ""
      "mode" is "empty_query"
  if state.scope_project_conflict is true:
    set state.loading is false
    delete "Notice" where true
    create "Notice" with map:
      "id" is "current"
      "message" is "Multiple #project mentions found. Mention one project in a single prompt."
    as notice_project_scope_conflict
    return map:
      "answer_text" is ""
      "mode" is "project_scope_conflict"
  let sync_status is call flow "rag_engine.sync_library":
    input:
    output:
      status
  let projects_status is call flow "rag_engine.ensure_projects":
    input:
    output:
      status
  if state.scope_project_id is "":
    set state.scope_project_id is state.active_project_id
  find "Project" where id is state.scope_project_id
  let scoped_project_count is list length of project_results
  if scoped_project_count is 0:
    set state.scope_project_id is state.active_project_id
  find "Project" where id is state.scope_project_id
  let active_scope_project_count is list length of project_results
  if active_scope_project_count is greater than 0:
    let active_scope_project is list get project_results at 0
    if state.scope_project_label is "":
      set state.scope_project_label is active_scope_project.name
  set state.needs_auto_ingest is false
  find "ProjectBinding" where project_id is state.scope_project_id
  set state.active_project_upload_ids is list:
  for each binding in projectbinding_results:
    set state.active_project_upload_ids is list append state.active_project_upload_ids with binding.upload_id

  set state.selected_docs_for_query is list:
  set state.scoped_docs_outside_project is list:
  let scoped_document_count is list length of state.scope_document_ids
  if scoped_document_count is greater than 0:
    find "DocumentLibrary" where true
    for each selected_doc in documentlibrary_results:
      set state.in_scoped_documents is false
      for each scoped_upload_id in state.scope_document_ids:
        if scoped_upload_id is selected_doc.upload_id:
          set state.in_scoped_documents is true
      if state.in_scoped_documents is true:
        set state.in_active_project is false
        for each active_upload_id in state.active_project_upload_ids:
          if active_upload_id is selected_doc.upload_id:
            set state.in_active_project is true
        if state.in_active_project is true:
          set state.selected_docs_for_query is list append state.selected_docs_for_query with selected_doc
        else:
          set state.scoped_docs_outside_project is list append state.scoped_docs_outside_project with selected_doc

    let outside_scope_count is list length of state.scoped_docs_outside_project
    if outside_scope_count is greater than 0:
      if state.scope_document_mode is "add":
        for each outside_doc in state.scoped_docs_outside_project:
          find "ProjectBinding" where id is state.scope_project_id + "::" + outside_doc.upload_id
          let outside_binding_count is list length of projectbinding_results
          if outside_binding_count is 0:
            create "ProjectBinding" with map:
              "id" is state.scope_project_id + "::" + outside_doc.upload_id
              "project_id" is state.scope_project_id
              "upload_id" is outside_doc.upload_id
            as outside_scope_binding
          set state.selected_docs_for_query is list append state.selected_docs_for_query with outside_doc
          set state.active_project_upload_ids is list append state.active_project_upload_ids with outside_doc.upload_id

        delete "Notice" where true
        create "Notice" with map:
          "id" is "current"
          "message" is "Added @document sources to #" + state.scope_project_label + " for future chats."
        as notice_scope_docs_added
      else:
        for each outside_doc in state.scoped_docs_outside_project:
          set state.selected_docs_for_query is list append state.selected_docs_for_query with outside_doc

        delete "Notice" where true
        create "Notice" with map:
          "id" is "current"
          "message" is "Using @document sources once without adding them to the project."
        as notice_scope_docs_once
  set state.selected_scope_count is list length of state.selected_docs_for_query
  if scoped_document_count is greater than 0:
    if state.selected_scope_count is 0:
      set state.loading is false
      delete "Notice" where true
      create "Notice" with map:
        "id" is "current"
        "message" is "No documents matched the @document scope."
      as notice_missing_document_scope
      return map:
        "answer_text" is ""
        "mode" is "document_scope_missing"
  if state.selected_scope_count is 0:
    find "DocumentLibrary" where selected is true
    for each selected_doc in documentlibrary_results:
      set state.in_active_project is false
      for each active_upload_id in state.active_project_upload_ids:
        if active_upload_id is selected_doc.upload_id:
          set state.in_active_project is true
      if state.in_active_project is true:
        set state.selected_docs_for_query is list append state.selected_docs_for_query with selected_doc

    set state.selected_scope_count is list length of state.selected_docs_for_query
  if state.selected_scope_count is 0:
    find "DocumentLibrary" where true
    set state.available_scope_docs is list:
    for each available_doc in documentlibrary_results:
      set state.in_active_project is false
      for each active_upload_id in state.active_project_upload_ids:
        if active_upload_id is available_doc.upload_id:
          set state.in_active_project is true
      if state.in_active_project is true:
        set state.available_scope_docs is list append state.available_scope_docs with available_doc

    let available_scope_count is list length of state.available_scope_docs
    if available_scope_count is greater than 0:
      set state.selected_docs_for_query is state.available_scope_docs

      delete "Notice" where true
      create "Notice" with map:
        "id" is "current"
        "message" is "No sources were marked in scope for the active project. Using project sources for this answer."
      as notice_scope_fallback

  for each selected_doc in state.selected_docs_for_query:
    if selected_doc.status is not "indexed":
      set state.needs_auto_ingest is true
  if state.needs_auto_ingest is true:
    let ingest_status is call flow "rag_engine.ingest_selected":
      input:
      output:
        status
    if scoped_document_count is greater than 0:
      find "DocumentLibrary" where true
      set state.selected_docs_for_query is list:
      for each selected_doc in documentlibrary_results:
        set state.in_scoped_documents is false
        for each scoped_upload_id in state.scope_document_ids:
          if scoped_upload_id is selected_doc.upload_id:
            set state.in_scoped_documents is true
        if state.in_scoped_documents is true:
          set state.selected_docs_for_query is list append state.selected_docs_for_query with selected_doc
    else:
      find "DocumentLibrary" where selected is true
      set state.selected_docs_for_query is list:
      for each selected_doc in documentlibrary_results:
        set state.in_active_project is false
        for each active_upload_id in state.active_project_upload_ids:
          if active_upload_id is selected_doc.upload_id:
            set state.in_active_project is true
        if state.in_active_project is true:
          set state.selected_docs_for_query is list append state.selected_docs_for_query with selected_doc
  set state.last_query is state.q
  set state.user_prompt is state.q
  if state.raw_message is not "":
    set state.user_prompt is state.raw_message
  set state.user_message with:
    role is "user"
    content is state.user_prompt
    actions is list: "copy", "expand"
    attachments is list:
    citations is list:
    trust is false
  try:
    let history is state.chat.messages
    set state.chat.messages is list append history with state.user_message
  with catch err:
    set state.chat.messages is list:
      state.user_message
  delete "RetrievalCandidate" where true
  delete "RetrievalCandidateView" where true
  delete "RankingDecision" where true
  delete "ExplainSummary" where true
  delete "ExplainCandidate" where true
  find "Question" where true
  let question_count is list length of question_results
  set state.query_id is question_count + 1
  set state.query_route is "lookup"
  set state.query_keywords is list:
    "document"
    "source"
    "evidence"
  if state.q is "compare indexing and retrieval in this corpus":
    set state.query_route is "comparison"
    set state.query_keywords is list:
      "compare"
      "indexing"
      "retrieval"
      "corpus"
  else:
    if state.q is "summarize the strongest evidence":
      set state.query_route is "summary"
      set state.query_keywords is list:
        "summarize"
        "strongest"
        "evidence"
        "summary"
    else:
      if state.q is "what does deterministic replay mean here" or state.q is "what is deterministic replay":
        set state.query_route is "definition"
        set state.query_keywords is list:
          "deterministic"
          "replay"
          "candidate"
          "ordering"
      else:
        if state.q is "runtime enforces citations":
          set state.query_route is "definition"
          set state.query_keywords is list:
            "runtime"
            "enforces"
            "citations"
            "trust"
  create "Question" with map:
    "id" is state.query_id
    "query" is state.q
    "route" is state.query_route
    "source_scope" is state.scope_project_id
  as question_row
  let selected_docs is state.selected_docs_for_query
  set state.scope_docs is list:
  set state.active_upload_ids is list:
  try:
    let active_tags is state.tag.active
    set state.active_tags is active_tags
  with catch err:
    set state.active_tags is list:
      "product"
      "policy"
      "general"
  let active_tag_count is list length of state.active_tags
  for each doc in selected_docs:
    set state.include_doc is false
    if active_tag_count is 0:
      set state.include_doc is true
    else:
      for each active_tag in state.active_tags:
        if doc.primary_tag is active_tag:
          set state.include_doc is true
    if state.include_doc is true:
      set state.scope_docs is list append state.scope_docs with doc
      set state.active_upload_ids is list append state.active_upload_ids with doc.upload_id

  let filtered_scope_count is list length of state.scope_docs
  if filtered_scope_count is 0:
    let selected_count is list length of selected_docs
    if selected_count is greater than 0:
      set state.scope_docs is selected_docs
      set state.active_upload_ids is list:
      for each fallback_doc in selected_docs:
        set state.active_upload_ids is list append state.active_upload_ids with fallback_doc.upload_id

      delete "Notice" where true
      create "Notice" with map:
        "id" is "current"
        "message" is "No sources matched active tag filters. Using selected sources for this answer."
      as notice_filter_fallback

  create "QueryProfile" with map:
    "id" is state.query_id
    "raw_query" is state.q
    "normalized_query" is state.q
    "route" is state.query_route
    "keywords" is state.query_keywords
    "active_documents" is state.active_upload_ids
    "active_tags" is state.active_tags
  as profile_row
  set state.answer_text is ""
  set state.answer_mode is "no_selection"
  set state.answer_citations is list:
  set state.answer_confidence is 0
  set state.answer_source_count is 0
  set state.answer_trust_score is 0
  set state.answer_trust_label is "No Support"
  set state.answer_trusted is false
  set state.answer.query is state.q
  set state.answer.answer_text is ""
  set state.answer.citations is list:
  set state.answer.trusted is false
  set state.answer.trust_score is 0
  set state.answer.source_count is 0
  set state.answer.mode is "no_selection"
  let scoped_count is list length of state.scope_docs
  if scoped_count is 0:
    set state.answer_text is "No selected sources match your active tag filters."
    set state.answer_mode is "no_selection"
  else:
    let chunks is list:
    try:
      let known_index is state.index
      let chunks is map get known_index key "chunks"
    with catch err:
      set chunks is list:
    set state.active_chunks is list:
    for each chunk in chunks:
      for each doc in state.scope_docs:
        set state.include_chunk is false
        if doc.upload_id is chunk.upload_id:
          if doc.status is "indexed":
            set state.include_chunk is true
          else:
            if doc.status is "failed":
              if chunk.ingestion_phase is "fallback":
                set state.include_chunk is true
        if state.include_chunk is true:
          set state.chunk_row with:
            chunk_id is chunk.chunk_id
            upload_id is chunk.upload_id
            document_id is chunk.document_id
            source_name is chunk.source_name
            page_number is chunk.page_number
            chunk_index is chunk.chunk_index
            ingestion_phase is chunk.ingestion_phase
            snippet is chunk.text
            keywords is chunk.keywords
            source_weight is doc.weight
            tag is doc.primary_tag
          set state.active_chunks is list append state.active_chunks with state.chunk_row
    let active_chunk_count is list length of state.active_chunks
    if active_chunk_count is 0:
      set state.answer_text is "No indexed chunks are available in the active scope yet. Try again in a moment."
      set state.answer_mode is "no_indexed_chunks"
    else:
      set state.active_index with:
        chunks is state.active_chunks
      set state.semantic_rows is list:
      try:
        let retrieval_out is call pipeline "retrieval":
          input:
            query is state.q
            limit is 50
            tier is "auto"
            index is state.active_index
          output:
            report
        let retrieval_report is map get retrieval_out key "report"
        let semantic_results is map get retrieval_report key "results"
        set state.semantic_rank_counter is 0
        for each result in semantic_results:
          set state.semantic_rank_counter is state.semantic_rank_counter + 1
          set state.chunk_id is result.chunk_id
          set state.semantic_row with:
            chunk_id is state.chunk_id
            upload_id is ""
            document_id is ""
            source_name is ""
            page_number is 1
            chunk_index is 1
            ingestion_phase is "indexed"
            snippet is ""
            semantic_rank is state.semantic_rank_counter
            semantic_score is 101 - state.semantic_rank_counter
            source_weight is 1
            tag is "general"
          for each chunk in state.active_chunks:
            if chunk.chunk_id is state.chunk_id:
              set state.semantic_row with:
                chunk_id is chunk.chunk_id
                upload_id is chunk.upload_id
                document_id is chunk.document_id
                source_name is chunk.source_name
                page_number is chunk.page_number
                chunk_index is chunk.chunk_index
                ingestion_phase is chunk.ingestion_phase
                snippet is chunk.snippet
                semantic_rank is state.semantic_rank_counter
                semantic_score is 101 - state.semantic_rank_counter
                source_weight is chunk.source_weight
                tag is chunk.tag
          set state.semantic_rows is list append state.semantic_rows with state.semantic_row
      with catch err:
        set state.semantic_rows is list:
      set state.semantic_rows_unique is list:
      for each sem in state.semantic_rows:
        set state.semantic_exists is false
        for each unique_sem in state.semantic_rows_unique:
          if unique_sem.chunk_id is sem.chunk_id:
            set state.semantic_exists is true
        if state.semantic_exists is false:
          set state.semantic_rows_unique is list append state.semantic_rows_unique with sem
      set state.semantic_rows is state.semantic_rows_unique
      order state.semantic_rows by semantic_score from highest to lowest
      keep first state.retrieval.semantic_k items
      set state.lexical_rows is list:
      set state.lexical_rank_counter is 0
      for each chunk in state.active_chunks:
        set state.hit_count is 0
        for each qk in state.query_keywords:
          for each ck in chunk.keywords:
            if qk is ck:
              set state.hit_count is state.hit_count + 1
        if state.hit_count is greater than 0:
          set state.lexical_rank_counter is state.lexical_rank_counter + 1
          set state.lex_row with:
            chunk_id is chunk.chunk_id
            upload_id is chunk.upload_id
            document_id is chunk.document_id
            source_name is chunk.source_name
            page_number is chunk.page_number
            chunk_index is chunk.chunk_index
            ingestion_phase is chunk.ingestion_phase
            snippet is chunk.snippet
            lexical_rank is state.lexical_rank_counter
            lexical_hits is state.hit_count
            lexical_score is state.hit_count
            source_weight is chunk.source_weight
            tag is chunk.tag
          set state.lexical_rows is list append state.lexical_rows with state.lex_row
      order state.lexical_rows by lexical_hits from highest to lowest
      keep first state.retrieval.lexical_k items
      set state.semantic_count is list length of state.semantic_rows
      set state.lexical_count is list length of state.lexical_rows
      for each sem in state.semantic_rows:
        create "RetrievalCandidate" with map:
          "query_id" is state.query_id
          "mode" is "semantic"
          "rank" is sem.semantic_rank
          "chunk_id" is sem.chunk_id
          "document_id" is sem.document_id
          "source_name" is sem.source_name
          "source_id" is sem.upload_id
          "tag" is sem.tag
          "page_number" is sem.page_number
          "chunk_index" is sem.chunk_index
          "ingestion_phase" is sem.ingestion_phase
          "tier" is "semantic"
          "semantic_rank" is sem.semantic_rank
          "lexical_rank" is 999
          "lexical_hits" is 0
          "semantic_score" is sem.semantic_score
          "lexical_score" is 0
          "source_weight" is sem.source_weight
          "merged_score" is sem.semantic_score
          "selected" is false
          "reason" is "Semantic candidate"
          "snippet" is sem.snippet
        as semantic_candidate
      for each lex in state.lexical_rows:
        create "RetrievalCandidate" with map:
          "query_id" is state.query_id
          "mode" is "lexical"
          "rank" is lex.lexical_rank
          "chunk_id" is lex.chunk_id
          "document_id" is lex.document_id
          "source_name" is lex.source_name
          "source_id" is lex.upload_id
          "tag" is lex.tag
          "page_number" is lex.page_number
          "chunk_index" is lex.chunk_index
          "ingestion_phase" is lex.ingestion_phase
          "tier" is "lexical"
          "semantic_rank" is 999
          "lexical_rank" is lex.lexical_rank
          "lexical_hits" is lex.lexical_hits
          "semantic_score" is 0
          "lexical_score" is lex.lexical_score
          "source_weight" is lex.source_weight
          "merged_score" is lex.lexical_score
          "selected" is false
          "reason" is "Lexical candidate"
          "snippet" is lex.snippet
        as lexical_candidate
      set state.semantic_weight is state.retrieval.semantic_weight
      set state.lexical_weight is 100 - state.semantic_weight
      set state.merged_rows is list:
      for each sem in state.semantic_rows:
        set state.lexical_hits is 0
        set state.lexical_rank is 999
        for each lex in state.lexical_rows:
          if lex.chunk_id is sem.chunk_id:
            set state.lexical_hits is lex.lexical_hits
            set state.lexical_rank is lex.lexical_rank
        set state.semantic_component is (sem.semantic_score * state.semantic_weight) / 100
        set state.lexical_component is (state.lexical_hits * state.lexical_weight) / 100
        set state.merged_score is state.semantic_component + state.lexical_component + (sem.source_weight * 2)
        set state.tier is "semantic_only"
        if state.lexical_hits is greater than 0:
          set state.tier is "hybrid_match"
        set state.merged_row with:
          chunk_id is sem.chunk_id
          upload_id is sem.upload_id
          document_id is sem.document_id
          source_name is sem.source_name
          page_number is sem.page_number
          chunk_index is sem.chunk_index
          ingestion_phase is sem.ingestion_phase
          snippet is sem.snippet
          tag is sem.tag
          tier is state.tier
          semantic_rank is sem.semantic_rank
          lexical_rank is state.lexical_rank
          lexical_hits is state.lexical_hits
          semantic_score is sem.semantic_score
          lexical_score is state.lexical_hits
          source_weight is sem.source_weight
          merged_score is state.merged_score
        set state.merged_rows is list append state.merged_rows with state.merged_row
      for each lex in state.lexical_rows:
        set state.exists is false
        for each merged in state.merged_rows:
          if merged.chunk_id is lex.chunk_id:
            set state.exists is true
        if state.exists is false:
          set state.merged_score is (lex.lexical_score * state.lexical_weight) / 100 + (lex.source_weight * 2)
          set state.merged_row with:
            chunk_id is lex.chunk_id
            upload_id is lex.upload_id
            document_id is lex.document_id
            source_name is lex.source_name
            page_number is lex.page_number
            chunk_index is lex.chunk_index
            ingestion_phase is lex.ingestion_phase
            snippet is lex.snippet
            tag is lex.tag
            tier is "lexical_only"
            semantic_rank is 999
            lexical_rank is lex.lexical_rank
            lexical_hits is lex.lexical_hits
            semantic_score is 0
            lexical_score is lex.lexical_score
            source_weight is lex.source_weight
            merged_score is state.merged_score
          set state.merged_rows is list append state.merged_rows with state.merged_row
      order state.merged_rows by merged_score from highest to lowest
      set state.rank_counter is 0
      set state.final_rows is list:
      for each ranked in state.merged_rows:
        set state.rank_counter is state.rank_counter + 1
        set state.selected is false
        if state.rank_counter is at most state.retrieval.final_top_k:
          set state.selected is true
          set state.final_rows is list append state.final_rows with ranked
        set state.reason is "Ranked by weighted semantic and lexical signals."
        if ranked.tier is "hybrid_match":
          set state.reason is "Semantic and lexical overlap agree."
        else:
          if ranked.tier is "lexical_only":
            set state.reason is "Lexical evidence only."
        create "RankingDecision" with map:
          "query_id" is state.query_id
          "rank" is state.rank_counter
          "chunk_id" is ranked.chunk_id
          "tier" is ranked.tier
          "merged_score" is ranked.merged_score
          "selected" is state.selected
          "reason" is state.reason
        as ranking_row
        create "RetrievalCandidate" with map:
          "query_id" is state.query_id
          "mode" is "final"
          "rank" is state.rank_counter
          "chunk_id" is ranked.chunk_id
          "document_id" is ranked.document_id
          "source_name" is ranked.source_name
          "source_id" is ranked.upload_id
          "tag" is ranked.tag
          "page_number" is ranked.page_number
          "chunk_index" is ranked.chunk_index
          "ingestion_phase" is ranked.ingestion_phase
          "tier" is ranked.tier
          "semantic_rank" is ranked.semantic_rank
          "lexical_rank" is ranked.lexical_rank
          "lexical_hits" is ranked.lexical_hits
          "semantic_score" is ranked.semantic_score
          "lexical_score" is ranked.lexical_score
          "source_weight" is ranked.source_weight
          "merged_score" is ranked.merged_score
          "selected" is state.selected
          "reason" is state.reason
          "snippet" is ranked.snippet
        as final_candidate
        create "ExplainCandidate" with map:
          "query" is state.q
          "order" is state.rank_counter
          "chunk_id" is ranked.chunk_id
          "ingestion_phase" is ranked.ingestion_phase
          "keyword_overlap" is ranked.lexical_hits
          "page_number" is ranked.page_number
          "chunk_index" is ranked.chunk_index
          "decision" is state.reason
          "reason" is state.reason
        as explain_row

      if state.rank_counter is 0:
        set state.fallback_rank is 0
        for each fallback_chunk in chunks:
          set state.include_fallback_chunk is false
          set state.fallback_source_weight is 1
          set state.fallback_tag is "general"
          for each scope_doc in state.scope_docs:
            if scope_doc.upload_id is fallback_chunk.upload_id:
              if scope_doc.status is "indexed":
                set state.include_fallback_chunk is true
                set state.fallback_source_weight is scope_doc.weight
                set state.fallback_tag is scope_doc.primary_tag
              else:
                if scope_doc.status is "failed":
                  if fallback_chunk.ingestion_phase is "fallback":
                    set state.include_fallback_chunk is true
                    set state.fallback_source_weight is scope_doc.weight
                    set state.fallback_tag is scope_doc.primary_tag
          if state.include_fallback_chunk is true:
            set state.fallback_rank is state.fallback_rank + 1
            if state.fallback_rank is at most state.retrieval.final_top_k:
              set state.fallback_snippet is ""
              try:
                let fallback_text is fallback_chunk.text
                if fallback_text is not "":
                  set state.fallback_snippet is fallback_text
              with catch err:
                set state.fallback_snippet is state.fallback_snippet
              if state.fallback_snippet is "":
                try:
                  let fallback_existing_snippet is fallback_chunk.snippet
                  if fallback_existing_snippet is not "":
                    set state.fallback_snippet is fallback_existing_snippet
                with catch err:
                  set state.fallback_snippet is state.fallback_snippet

              set state.fallback_row with:
                chunk_id is fallback_chunk.chunk_id
                upload_id is fallback_chunk.upload_id
                document_id is fallback_chunk.document_id
                source_name is fallback_chunk.source_name
                page_number is fallback_chunk.page_number
                chunk_index is fallback_chunk.chunk_index
                ingestion_phase is fallback_chunk.ingestion_phase
                snippet is state.fallback_snippet
                tag is state.fallback_tag
                tier is "fallback_order"
                semantic_rank is 999
                lexical_rank is 999
                lexical_hits is 0
                semantic_score is 0
                lexical_score is 0
                source_weight is state.fallback_source_weight
                merged_score is state.fallback_source_weight
              set state.final_rows is list append state.final_rows with state.fallback_row
              set state.reason is "Fallback order from indexed scope."
              create "RankingDecision" with map:
                "query_id" is state.query_id
                "rank" is state.fallback_rank
                "chunk_id" is fallback_chunk.chunk_id
                "tier" is "fallback_order"
                "merged_score" is state.fallback_source_weight
                "selected" is true
                "reason" is state.reason
              as fallback_ranking_row
              create "RetrievalCandidate" with map:
                "query_id" is state.query_id
                "mode" is "final"
                "rank" is state.fallback_rank
                "chunk_id" is fallback_chunk.chunk_id
                "document_id" is fallback_chunk.document_id
                "source_name" is fallback_chunk.source_name
                "source_id" is fallback_chunk.upload_id
                "tag" is state.fallback_tag
                "page_number" is fallback_chunk.page_number
                "chunk_index" is fallback_chunk.chunk_index
                "ingestion_phase" is fallback_chunk.ingestion_phase
                "tier" is "fallback_order"
                "semantic_rank" is 999
                "lexical_rank" is 999
                "lexical_hits" is 0
                "semantic_score" is 0
                "lexical_score" is 0
                "source_weight" is state.fallback_source_weight
                "merged_score" is state.fallback_source_weight
                "selected" is true
                "reason" is state.reason
                "snippet" is state.fallback_snippet
              as fallback_final_candidate
              create "ExplainCandidate" with map:
                "query" is state.q
                "order" is state.fallback_rank
                "chunk_id" is fallback_chunk.chunk_id
                "ingestion_phase" is fallback_chunk.ingestion_phase
                "keyword_overlap" is 0
                "page_number" is fallback_chunk.page_number
                "chunk_index" is fallback_chunk.chunk_index
                "decision" is state.reason
                "reason" is state.reason
              as fallback_explain_row
      let finalize_status is call flow "rag_engine.finalize_answer_state":
        input:
        output:
          status
  set state.loading is false
  if state.answer_text is "":
    set state.answer_text is "No grounded support found in indexed sources for this query."
  set state.answer.query is state.q
  set state.answer.answer_text is state.answer_text
  set state.answer.citations is state.answer_citations
  set state.answer.trusted is state.answer_trusted
  set state.answer.trust_score is state.answer_trust_score
  set state.answer.source_count is state.answer_source_count
  set state.answer.mode is state.answer_mode
  set state.assistant_has_sources is false
  let assistant_citation_count is list length of state.answer_citations
  if assistant_citation_count is greater than 0:
    if state.answer_mode is not "fallback_only":
      set state.assistant_has_sources is true
  set state.assistant_actions is list:
    "copy"
    "expand"
  if state.assistant_has_sources is true:
    set state.assistant_actions is list append state.assistant_actions with "view_sources"
  set state.scope_indicator is ""
  if state.scope_project_label is not "":
    set state.scope_indicator is "Scope: #" + state.scope_project_label
  else:
    if state.scope_project_id is not "":
      set state.scope_indicator is "Scope: #" + state.scope_project_id
  let scope_document_count_for_indicator is list length of state.scope_document_ids
  if scope_document_count_for_indicator is greater than 0:
    if state.scope_indicator is "":
      set state.scope_indicator is "Scope: @documents"
    else:
      set state.scope_indicator is state.scope_indicator + " + @documents"
  set state.assistant_content is state.answer_text
  if state.scope_indicator is not "":
    set state.assistant_content is state.scope_indicator + "\n" + state.answer_text
  set state.assistant_message with:
    role is "assistant"
    content is state.assistant_content
    actions is state.assistant_actions
    attachments is list:
    citations is state.answer_citations
    trust is false
  try:
    let history_after_query is state.chat.messages
    set state.chat.messages is list append history_after_query with state.assistant_message
  with catch err:
    set state.chat.messages is list:
      state.assistant_message
  delete "Notice" where true
  if state.answer_mode is "no_selection":
    create "Notice" with map:
      "id" is "current"
      "message" is "Select and index at least one source before asking."
    as notice_no_selection
  else:
    if state.answer_mode is "no_indexed_chunks":
      create "Notice" with map:
        "id" is "current"
        "message" is "No indexed chunks in active scope yet. Try again in a moment."
      as notice_no_chunks
    else:
      if state.answer_mode is "fallback_only":
        create "Notice" with map:
          "id" is "current"
          "message" is "Fallback chunk only. Upload searchable/OCR text, re-index, then ask again."
        as notice_fallback_only
      else:
        create "Notice" with map:
          "id" is "current"
          "message" is "Answer ready with inline citations and trust indicator."
        as notice_answer
  return map:
    "answer_text" is state.answer_text
    "mode" is state.answer_mode
